{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozVSXkfVnttc"
   },
   "source": [
    "# Model1 CNN+LSTM\n",
    "version 0.1.b.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vcLcTthG3-3"
   },
   "source": [
    "## Implementation detals\n",
    "- Input size: -1 x 2 x 90 x 100\n",
    "- Output size: -1 x 1\n",
    "<br></br>\n",
    "- X: CSI (magnitude + phase)\n",
    "- Y: side label\n",
    "## Version Info\n",
    "- Mapping from CSI to side labels (-1, 0, 1)\n",
    "- Only uses dynamic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7645,
     "status": "ok",
     "timestamp": 1671664006567,
     "user": {
      "displayName": "曹冠宇",
      "userId": "04420153168815849534"
     },
     "user_tz": -540
    },
    "id": "Ruor2R1Gn000",
    "outputId": "ef6b4f9c-e0c9-492d-cf54-51c7b279b709"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "# !pip install torchinfo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnZopCypFbgq"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zNGMVyA-KvTt"
   },
   "outputs": [],
   "source": [
    "class MyEncodeCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyEncodeCNN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=(3, 1), padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # No Padding\n",
    "            # No Pooling\n",
    "            # In = 90 * 100 * 1\n",
    "            # Out = 30 * 98 * 32\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # No Padding\n",
    "            # No Pooling\n",
    "            # In = 30 * 98 * 32\n",
    "            # Out = 26 * 94 * 64\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=5, stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # No Padding\n",
    "            # No Pooling\n",
    "            # In = 26 * 94 * 64\n",
    "            # Out = 22 * 90 * 32\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 1, kernel_size=5, stride=(1, 1), padding=0),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            # No Padding\n",
    "            # No Pooling\n",
    "            # In = 22 * 90 * 32\n",
    "            # Out = 18 * 86 * 1\n",
    "        )\n",
    "\n",
    "        self.layerfc = nn.Sequential(\n",
    "            nn.Linear(18*86, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 32)\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # size_x = batch_size * 18 * 86\n",
    "        # x = self.dropout(x)\n",
    "        # x = self.layerfc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyEncodeLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyEncodeLSTM, self).__init__()\n",
    "\n",
    "        self.hidden_size = 128\n",
    "        self.num_layers = 2\n",
    "\n",
    "        self.layer = nn.LSTM(36, self.hidden_size, self.num_layers, batch_first=True, dropout=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, (final_hidden_state, final_cell_state)  = self.layer(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MyEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyEncoder, self).__init__()\n",
    "        self.cnn1 = MyEncodeCNN()\n",
    "        self.cnn2 = MyEncodeCNN()\n",
    "        self.lstm = MyEncodeLSTM()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.chunk(x.view(-1, 2, 90, 100), 2, dim=1)\n",
    "        x1 = self.cnn1.forward(x[0])\n",
    "        x2 = self.cnn2.forward(x[1])\n",
    "\n",
    "        # size_x = batch_size * 18 * 86\n",
    "\n",
    "        out = torch.cat([x1, x2], dim=2).transpose(1, 2).view(-1, 86, 36)\n",
    "        #size_out = batch_size * 128 * 86\n",
    "        out = self.lstm.forward(out)\n",
    "        \n",
    "        return out[:, -1, :]\n",
    "\n",
    "\n",
    "class MyDecodeFC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDecodeFC, self).__init__()\n",
    "\n",
    "        self.fclayers = nn.Sequential(\n",
    "            nn.Linear(128, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),)\n",
    "        \n",
    "        self.onehotout = nn.Sequential(\n",
    "            nn.Linear(4096, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Softmax(dim=1)\n",
    "         )\n",
    "        \n",
    "        self.singleout = nn.Sequential(\n",
    "            nn.Linear(4096, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fclayers(x)\n",
    "        x = self.onehotout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        self.encoder = MyEncoder()\n",
    "        self.decoder = MyDecodeFC()\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z) \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1671636390748,
     "user": {
      "displayName": "曹冠宇",
      "userId": "04420153168815849534"
     },
     "user_tz": -540
    },
    "id": "C7tCrrQqvV3i",
    "outputId": "55705461-a3cc-4596-de22-348c04d96e2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "MyModel                                  [1, 3]                    --\n",
       "├─MyEncoder: 1-1                         [1, 128]                  --\n",
       "│    └─MyEncodeCNN: 2-1                  --                        202,400\n",
       "│    │    └─Sequential: 3-1              [1, 32, 30, 98]           384\n",
       "│    │    └─Sequential: 3-2              [1, 64, 26, 94]           51,392\n",
       "│    │    └─Sequential: 3-3              [1, 32, 22, 90]           51,296\n",
       "│    │    └─Sequential: 3-4              [1, 1, 18, 86]            803\n",
       "│    └─MyEncodeCNN: 2-2                  --                        202,400\n",
       "│    │    └─Sequential: 3-5              [1, 32, 30, 98]           384\n",
       "│    │    └─Sequential: 3-6              [1, 64, 26, 94]           51,392\n",
       "│    │    └─Sequential: 3-7              [1, 32, 22, 90]           51,296\n",
       "│    │    └─Sequential: 3-8              [1, 1, 18, 86]            803\n",
       "│    └─MyEncodeLSTM: 2-3                 --                        --\n",
       "│    │    └─LSTM: 3-9                    [1, 86, 128]              217,088\n",
       "├─MyDecodeFC: 1-2                        [1, 3]                    4,097\n",
       "│    └─Sequential: 2-4                   [1, 4096]                 --\n",
       "│    │    └─Linear: 3-10                 [1, 4096]                 528,384\n",
       "│    │    └─ReLU: 3-11                   [1, 4096]                 --\n",
       "│    │    └─Linear: 3-12                 [1, 4096]                 16,781,312\n",
       "│    │    └─ReLU: 3-13                   [1, 4096]                 --\n",
       "│    └─Sequential: 2-5                   [1, 3]                    --\n",
       "│    │    └─Linear: 3-14                 [1, 3]                    12,291\n",
       "│    │    └─ReLU: 3-15                   [1, 3]                    --\n",
       "│    │    └─Softmax: 3-16                [1, 3]                    --\n",
       "==========================================================================================\n",
       "Total params: 18,155,722\n",
       "Trainable params: 18,155,722\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 493.81\n",
       "==========================================================================================\n",
       "Input size (MB): 0.07\n",
       "Forward/backward pass size (MB): 10.25\n",
       "Params size (MB): 70.99\n",
       "Estimated Total Size (MB): 81.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = MyModel()\n",
    "summary(m1, input_size=(2, 90, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzNX5ISCFhBY"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10574,
     "status": "ok",
     "timestamp": 1671664054419,
     "user": {
      "displayName": "曹冠宇",
      "userId": "04420153168815849534"
     },
     "user_tz": -540
    },
    "id": "Qv4H17YcAR3I",
    "outputId": "43bbd323-54c0-47a3-e21e-3d2029ba7bf3"
   },
   "outputs": [],
   "source": [
    "# My Dataset\n",
    "\n",
    "class MyDataset(Data.Dataset):\n",
    "    def __init__(self, x_path, y_path, number=0):\n",
    "        self.seeds = None\n",
    "        self.data = self.load_data(x_path, y_path, number=number)\n",
    "        print('loaded')\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data['x'][index], self.data['y'][index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data['x'].shape[0]\n",
    "\n",
    "    def load_data(self, x_path, y_path, number):\n",
    "        x = np.load(x_path)\n",
    "        y = np.load(y_path)\n",
    "\n",
    "        if x.shape[0] == y.shape[0]:\n",
    "            total_count = x.shape[0]\n",
    "        else:\n",
    "            print(x.shape, y.shape, \"lengths not equal!\")\n",
    "            \n",
    "        if number != 0:\n",
    "            picked = np.random.choice(list(range(total_count)), size=number, replace=False)\n",
    "            self.seeds = picked\n",
    "            x = x[picked]\n",
    "            y = y[picked]\n",
    "\n",
    "        return {'x':x, 'y':y}\n",
    "    \n",
    "def split_loader(dataset, train_size, valid_size, test_size, batch_size):\n",
    "    train_dataset, valid_dataset, test_dataset = Data.random_split(dataset, [train_size, valid_size, test_size])\n",
    "    print(len(train_dataset), len(valid_dataset), len(test_dataset))\n",
    "    train_loader = Data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    valid_loader = Data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = Data.DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18918,
     "status": "ok",
     "timestamp": 1671664037687,
     "user": {
      "displayName": "曹冠宇",
      "userId": "04420153168815849534"
     },
     "user_tz": -540
    },
    "id": "3lkvH24vGZ8t",
    "outputId": "21098cf0-9111-4d5d-99f2-b9d453f6fe84",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sid.npy', 'csi.npy', '.ipynb_checkpoints', 'sid2.npy', 'sid_10.npy']\n"
     ]
    }
   ],
   "source": [
    "datadir = '../Dataset/0208make00/'\n",
    "print(os.listdir(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6H9dFQc8LhN1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "(3514, 2, 90, 100) (3514, 3)\n",
      "2459 702 353\n",
      "2459 702 353\n"
     ]
    }
   ],
   "source": [
    "mydata = MyDataset(datadir + 'csi.npy', datadir + 'sid_10.npy')\n",
    "print(mydata.data['x'].shape, mydata.data['y'].shape)\n",
    "\n",
    "train_size = int(len(mydata) * 0.7)\n",
    "valid_size = int(len(mydata) * 0.2)\n",
    "test_size = int(len(mydata)) - train_size - valid_size\n",
    "print(train_size, valid_size, test_size)\n",
    "\n",
    "train_loader, valid_loader, test_loader = split_loader(mydata, train_size, valid_size, test_size, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX TITAN X'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xy-67GwAFj5T"
   },
   "source": [
    "## Running gears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P5GAqZF5D3lL"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "class MyArgs:\n",
    "    def __init__(self, epochs=10, learning_rate=0.001):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args = MyArgs(epochs=1000, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lCvRd4pOFBzc"
   },
   "outputs": [],
   "source": [
    "# Model and Loss\n",
    "\n",
    "model = MyModel().to(args.device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_epochs_loss = []\n",
    "valid_epochs_loss = []\n",
    "\n",
    "# early_stopping = EarlyStopping(patience=args.patience,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UljtLCZzFR4P",
    "outputId": "02d3671f-7293-422f-de88-c0bd239043bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=999/1000,19/38of train, loss=31.270833969116212\n",
      "Total training time: 3098.2651178836823 sec\n"
     ]
    }
   ],
   "source": [
    "# Training and Saving\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    model.train()\n",
    "    train_epoch_loss = []\n",
    "    for idx,(data_x,data_y) in enumerate(train_loader,0):\n",
    "        data_x = data_x.to(torch.float32).to(args.device)\n",
    "        data_y = data_y.to(torch.float32).to(args.device)\n",
    "        outputs = model(data_x)\n",
    "        loss = criterion(outputs, data_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss.append(loss.item())\n",
    "        train_loss.append(loss.item())\n",
    "        if idx%(len(train_loader)//2)==0:\n",
    "            print(\"\\repoch={}/{},{}/{}of train, loss={}\".format(\n",
    "            epoch, args.epochs, idx, len(train_loader),loss.item()), end='')\n",
    "    train_epochs_loss.append(np.average(train_epoch_loss))\n",
    "  \n",
    "  #=====================valid============================\n",
    "model.eval()\n",
    "valid_epoch_loss = []\n",
    "for idx,(data_x,data_y) in enumerate(valid_loader,0):\n",
    "    data_x = data_x.to(torch.float32).to(args.device)\n",
    "    data_y = data_y.to(torch.float32).to(args.device)\n",
    "    outputs = model(data_x)\n",
    "    loss = criterion(outputs,data_y)\n",
    "    valid_epoch_loss.append(loss.item())\n",
    "    valid_loss.append(loss.item())\n",
    "valid_epochs_loss.append(np.average(valid_epoch_loss))\n",
    "\n",
    "  #==================early stopping======================\n",
    "  # early_stopping(valid_epochs_loss[-1],model=MyModel,path=r'')\n",
    "  # if early_stopping.early_stop:\n",
    "  #    print(\"Early stopping\")\n",
    "  #    break\n",
    "  #====================adjust lr========================\n",
    "lr_adjust = {\n",
    "    2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,\n",
    "    10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "}\n",
    "  #if epoch in lr_adjust.keys():\n",
    "  #    lr = lr_adjust[epoch]\n",
    "  #    for param_group in optimizer.param_groups:\n",
    "  #        param_group['lr'] = lr\n",
    "  #    print('Updating learning rate to {}'.format(lr))\n",
    "\n",
    "torch.save(model.state_dict(), '../Models/v01b2_ep300.pth')\n",
    "end = time.time()\n",
    "print(\"\\nTotal training time:\", end-start, \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "\n",
    "%matplotlib inline\n",
    "plt.clf()\n",
    "plt.suptitle(\"Training loss and Validation loss\")\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_epochs_loss[1:], 'b', label = 'training_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('#epoch')\n",
    "plt.legend()\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(valid_loss, 'b', label = 'validation_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('#iter')\n",
    "plt.legend()\n",
    "#plt.savefig(\"loss_900epoch_down.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600,) (2,)\n",
      "(22800,) (20,)\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train_epochs_loss).shape, np.array(valid_epochs_loss).shape)\n",
    "print(np.array(train_loss).shape, np.array(valid_loss).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'MyDecoder' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9d6c77c64210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#model = torch.load('../Models/v0_ep500_lr001.pth')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Models/v0_ep500_lr001.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    849\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'MyDecoder' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "# If you want to train from a certain checkpoint\n",
    "\n",
    "#model = torch.load('../Models/v0_ep500_lr001.pth')\n",
    "model.load_state_dict(torch.load('../Models/v0_ep500_lr001.pth'))\n",
    "model.cuda()\n",
    "\n",
    "# Reload the loss curve\n",
    "preserve = 500\n",
    "# 3 iter per epoch\n",
    "train_loss = train_loss[:preserve * 3]\n",
    "# discard following epoch values\n",
    "train_epochs_loss = train_epochs_loss[:preserve]\n",
    "\n",
    "# re-validate\n",
    "valid_loss = []\n",
    "valid_epochs_loss = []\n",
    "\n",
    "args = MyArgs(epochs=200, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation\n",
    "Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/353of test, loss=33.66666793823242"
     ]
    }
   ],
   "source": [
    "  #=====================test============================\n",
    "estimate = []\n",
    "test_loss = []\n",
    "ground_truth = []\n",
    "model.eval()\n",
    "for idx,(data_x,data_y) in enumerate(test_loader,0):\n",
    "    data_x = data_x.to(torch.float32).to(args.device)\n",
    "    data_y = data_y.to(torch.float32).to(args.device)\n",
    "    outputs = model(data_x)\n",
    "    loss = criterion(outputs,data_y)\n",
    "    estimate.append(outputs.cpu().detach().numpy().squeeze().tolist())\n",
    "    ground_truth.append(data_y.cpu().detach().numpy().squeeze().tolist())\n",
    "    test_loss.append(loss.item())\n",
    "    if idx%(len(test_loader)//5)==0:\n",
    "        print(\"\\r{}/{}of test, loss={}\".format(\n",
    "        idx, len(test_loader),loss.item()), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(30.5, 0.5, 'true')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "\n",
    "def fromonehot(inlist):\n",
    "    out = []\n",
    "    for item in inlist:\n",
    "        if np.argmax(item) == 0:\n",
    "            out.append(-1)\n",
    "        elif np.argmax(item) == 1:\n",
    "            out.append(0)\n",
    "        elif np.argmax(item) == 2:\n",
    "            out.append(1)\n",
    "    return out\n",
    "\n",
    "print(fromonehot(estimate))\n",
    "\n",
    "plt.figure()\n",
    "sns.set()\n",
    "f,ax=plt.subplots()\n",
    "cf = confusion_matrix(fromonehot(ground_truth), fromonehot(estimate))\n",
    "\n",
    "sns.heatmap(cf,annot=True,ax=ax) \n",
    "\n",
    "ax.set_title('confusion matrix') \n",
    "ax.set_xlabel('predict') \n",
    "ax.set_ylabel('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "data = torch.tensor(csis, dtype=torch.float32, device='cuda:1')\n",
    "for i in range(len(data)):\n",
    "    predictions = model(data[i])\n",
    "    pred = predictions.cpu().detach().numpy()[0, 0]\n",
    "    plt.figure()\n",
    "    plt.imshow(pred)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOu2+56/iaay+3ugFmvPoFz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
